"""LLM agent using GPT-4.1-mini with Structured Outputs and Function Calling."""
from typing import Dict, Any, List
import json
from openai import OpenAI
import os
from cachetools import TTLCache
from models.schemas import AgentResponseSchema, make_schema_strict
from data.handler import data_handler
from core.context import context_manager
from utils.arabic_normalizer import normalize_ar


class ChatAgent:
    """Chat agent using GPT-4.1-mini."""
    
    def __init__(self):
        """Initialize chat agent."""
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("OPENAI_API_KEY environment variable is required")
        self.client = OpenAI(api_key=api_key)
        self.model = os.getenv('LLM_MODEL_AGENT', 'gpt-4o-mini')
        self._schema = make_schema_strict(AgentResponseSchema.model_json_schema())
        # Cache responses for short window to reduce cost on repeated asks
        # TTL Ù‚ØµÙŠØ± (60 Ø«Ø§Ù†ÙŠØ©) Ù„Ø¶Ù…Ø§Ù† Ø±Ø¯ÙˆØ¯ Ø­Ø¯ÙŠØ«Ø© ÙˆÙ…ØªØ³Ù‚Ø©
        self._response_cache = TTLCache(maxsize=300, ttl=60)
    
    def generate_response(
        self,
        message: str,
        intent: str,
        entities: List[Dict[str, Any]],
        context: Dict[str, Any] = None,
        user_id: str = None,
        platform: str = None,
        conversation_history: List[Dict[str, Any]] = None
    ) -> AgentResponseSchema:
        """
        Generate response using LLM with Structured Outputs.
        
        Args:
            message: User message
            intent: Detected intent
            entities: Extracted entities
            context: Optional context
            
        Returns:
            AgentResponseSchema with response_text, needs_clarification, suggested_questions
        """
        # Quick cache for repeated messages (same intent + normalized message + entities)
        # Ù„Ø§ Ù†Ø³ØªØ®Ø¯Ù… cache Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø© Ø£Ùˆ Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ Ø³ÙŠØ§Ù‚
        cache_key = None
        try:
            # Ù„Ø§ Ù†Ø³ØªØ®Ø¯Ù… cache Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ conversation_history (ÙŠØ­ØªØ§Ø¬ Ø³ÙŠØ§Ù‚)
            if not conversation_history or len(conversation_history) == 0:
                norm_msg = normalize_ar(message) if message else ""
                ent_key = tuple(sorted([f"{e.get('type','')}:{e.get('value','')}" for e in entities]))
                cache_key = (intent, norm_msg, ent_key)
                if cache_key in self._response_cache:
                    cached = self._response_cache[cache_key]
                    return AgentResponseSchema(**cached)
        except Exception:
            pass

        FAST_INTENTS = {"greeting", "thanks", "goodbye"}
        if intent in FAST_INTENTS:
            if intent == "greeting":
                return AgentResponseSchema(
                    response_text="Ù‡Ù„Ø§ ÙˆØ§Ù„Ù„Ù‡ ğŸ‘‹ Ø´Ù„ÙˆÙ† Ø£Ù‚Ø¯Ø± Ø£Ø®Ø¯Ù…ÙƒØŸ ØªØ¨ÙŠ Ø£Ø·Ø¨Ø§Ø¡ ÙˆÙ„Ø§ Ø®Ø¯Ù…Ø§Øª ÙˆÙ„Ø§ ÙØ±ÙˆØ¹ØŸ",
                    needs_clarification=True,
                    suggested_questions=["Ø£Ø·Ø¨Ø§Ø¡", "Ø®Ø¯Ù…Ø§Øª", "ÙØ±ÙˆØ¹", "Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ø¯ÙˆØ§Ù…", "Ø­Ø¬Ø²"]
                )
            if intent == "thanks":
                return AgentResponseSchema(
                    response_text="Ø§Ù„Ø¹ÙÙˆ ÙˆØ§Ù„Ù„Ù‡ âœ… Ø¥Ø°Ø§ ØªØ¨ÙŠ Ø£ÙŠ Ø´ÙŠ Ø£Ù†Ø§ Ø­Ø§Ø¶Ø±.",
                    needs_clarification=False,
                    suggested_questions=["Ø£Ø·Ø¨Ø§Ø¡", "Ø®Ø¯Ù…Ø§Øª", "ÙØ±ÙˆØ¹", "Ø­Ø¬Ø²"]
                )
            if intent == "goodbye":
                return AgentResponseSchema(
                    response_text="Ø­ÙŠØ§Ùƒ Ø§Ù„Ù„Ù‡ ğŸ‘‹ Ø¨Ø£ÙŠ ÙˆÙ‚Øª ØªØ­ØªØ§Ø¬Ù†Ø§.",
                    needs_clarification=False,
                    suggested_questions=[]
                )

        system_prompt = """Ø£Ù†Øª Ù…ÙˆØ¸Ù Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ù…Ø­ØªØ±Ù ÙˆØ¯Ø§ÙØ¦ ÙÙŠ Ø¹ÙŠØ§Ø¯Ø© Ø¨Ù„Ùˆ Ø¯ÙŠÙ… ğŸ¥. Ù…Ù‡Ù…ØªÙƒ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø±Ø¶Ù‰ Ø¨ÙƒÙ„ ÙˆØ¯ ÙˆØ§Ø­ØªØ±Ø§ÙÙŠØ©.

Ø´Ø®ØµÙŠØªÙƒ ÙˆØ£Ø³Ù„ÙˆØ¨Ùƒ:
- Ø£Ù†Øª Ù…Ø­ØªØ±Ù ÙˆØ¯Ø§ÙØ¦ØŒ ØªØ³ØªØ®Ø¯Ù… Ù„ØºØ© Ø·Ø¨ÙŠØ¹ÙŠØ© ÙˆÙˆØ¯ÙˆØ¯Ø© Ù„ÙƒÙ† Ø§Ø­ØªØ±Ø§ÙÙŠØ©
- Ø¨Ù„Ù‡Ø¬Ø© Ù†Ø¬Ø¯ÙŠØ© Ø·Ø¨ÙŠØ¹ÙŠØ© ÙˆÙ…Ø±ÙŠØ­Ø©
- ØªÙØ§Ø¹Ù„ÙŠ ÙˆØ§Ø³ØªØ¨Ø§Ù‚ÙŠ: Ø§Ù‚ØªØ±Ø­ Ø®Ø·ÙˆØ§Øª ØªØ§Ù„ÙŠØ© Ø£Ùˆ Ø£Ø³Ø¦Ù„Ø© Ù…ÙÙŠØ¯Ø©
- Ø°ÙƒÙŠ ÙÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø³ÙŠØ§Ù‚: ØªØ±Ø¨Ø· Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ø¨Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
- Ù…Ø±Ù† ÙÙŠ Ø·ÙˆÙ„ Ø§Ù„Ø±Ø¯: Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„ (Ø¨Ø³ÙŠØ· = Ù‚ØµÙŠØ±ØŒ Ù…Ø¹Ù‚Ø¯ = Ø£Ø·ÙˆÙ„)

Ù‚ÙˆØ§Ø¹Ø¯ Ø£Ø³Ø§Ø³ÙŠØ© (Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹ Ù„Ù„Ø§ØªØ³Ø§Ù‚):
1) Ø·ÙˆÙ„ Ø§Ù„Ø±Ø¯ Ù…Ø±Ù†: 2-6 Ø¬Ù…Ù„ Ø­Ø³Ø¨ Ø§Ù„Ø­Ø§Ø¬Ø© (Ø£Ø³Ø¦Ù„Ø© Ø¨Ø³ÙŠØ·Ø© = 2-3 Ø¬Ù…Ù„ØŒ Ø£Ø³Ø¦Ù„Ø© Ù…Ø¹Ù‚Ø¯Ø© = 4-6 Ø¬Ù…Ù„)
2) Ù„Ø§ ØªØ®ØªØ±Ø¹ Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø©Ø› Ø§Ø³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
3) Ø¥Ø°Ø§ Ù…Ø§ ÙÙŠÙ‡ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ©: Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„ ØªÙˆØ¶ÙŠØ­ÙŠ ÙˆØ§Ø­Ø¯ + Ø§Ù‚ØªØ±Ø­ 2â€“4 Ø®ÙŠØ§Ø±Ø§Øª
4) Ù„Ø§ ØªØ¨Ø¯Ø£ Ø§Ù„Ø­Ø¬Ø² Ø¥Ù„Ø§ Ø¨Ø·Ù„Ø¨ ØµØ±ÙŠØ­ (\"Ø§Ø¨ÙŠ Ø§Ø­Ø¬Ø²\"/\"Ø­Ø¬Ø²\"/\"Ø§Ø¨ÙŠ Ù…ÙˆØ¹Ø¯\")
5) Ù‚ÙˆØ§Ø¦Ù… (Ø£Ø·Ø¨Ø§Ø¡/ÙØ±ÙˆØ¹/Ø®Ø¯Ù…Ø§Øª): Ø§Ø¹Ø±Ø¶ 3â€“6 Ø¹Ù†Ø§ØµØ± Ù…Ø®ØªØµØ±Ø© Ù…Ø¹ Ø£Ù‡Ù… Ù…Ø¹Ù„ÙˆÙ…Ø©
6) Ø¥ÙŠÙ…ÙˆØ¬ÙŠ Ù‚Ù„ÙŠÙ„Ø©: âœ… ğŸ“ â° ğŸ’° (Ø­Ø¯ Ø£Ù‚ØµÙ‰ 2)
7) **ÙƒÙ† Ù…ØªØ³Ù‚Ø§Ù‹**: Ù†ÙØ³ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„ = Ù†ÙØ³ Ù†ÙˆØ¹ Ø§Ù„Ø±Ø¯ (Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙŠØ©ØŒ ÙˆØ¯ÙˆØ¯Ø©ØŒ Ù…ÙÙŠØ¯Ø©)
8) **Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¯Ø§Ø¦Ù…Ø§Ù‹**: Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªÙˆÙØ±Ø©ØŒ Ø§Ø³ØªØ®Ø¯Ù…Ù‡Ø§. Ù„Ø§ ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„ØªØ®Ù…ÙŠÙ†

Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ Ø¨Ø°ÙƒØ§Ø¡:
- Ø§Ø±Ø¨Ø· Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ø¨Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
- Ø¥Ø°Ø§ Ø³Ø£Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ù† Ø´ÙŠØ¡ ØªÙ… Ø°ÙƒØ±Ù‡ Ø³Ø§Ø¨Ù‚Ø§Ù‹ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ Ù„ÙÙ‡Ù… Ù…Ø§ ÙŠÙ‚ØµØ¯Ù‡
- Ø£Ø¨Ø±Ø² Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ù…Ù† Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
- ÙƒÙ† Ø§Ø³ØªØ¨Ø§Ù‚ÙŠØ§Ù‹: Ø§Ù‚ØªØ±Ø­ Ø®Ø·ÙˆØ§Øª ØªØ§Ù„ÙŠØ© Ø£Ùˆ Ø£Ø³Ø¦Ù„Ø© Ù…ÙÙŠØ¯Ø©

Ø´ÙƒÙ„ Ø§Ù„Ø±Ø¯ Ø­Ø³Ø¨ intent:
- greeting: Ø±Ø­Ù‘Ø¨ Ø¨Ø³Ø±Ø¹Ø© ÙˆØ¯Ø§ÙØ¦ + Ø®ÙŠØ§Ø±Ø§Øª (Ø£Ø·Ø¨Ø§Ø¡/Ø®Ø¯Ù…Ø§Øª/ÙØ±ÙˆØ¹/Ø¯ÙˆØ§Ù…/Ø­Ø¬Ø²)
- doctor: Ù„Ùˆ doctor_name Ø§Ø¹Ø±Ø¶ Ø§Ù„ØªØ®ØµØµ + Ø§Ù„ÙØ±Ø¹ + Ø£ÙˆÙ‚Ø§Øª Ù…Ø®ØªØµØ±Ø© + Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù…ÙÙŠØ¯Ø©. Ù„Ùˆ Ù‚Ø§Ø¦Ù…Ø©/ØªØ®ØµØµ Ø§Ø¹Ø±Ø¶ 3â€“6 Ø£Ø³Ù…Ø§Ø¡ Ø«Ù… Ø§Ø³Ø£Ù„ Ø¹Ù† Ø§Ù„ØªØ®ØµØµ. **Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹:** Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† "Ù…ÙŠÙ† Ø§Ø­Ø³Ù†" Ø£Ùˆ "Ù…ÙŠÙ† Ø§ÙØ¶Ù„" Ø·Ø¨ÙŠØ¨ØŒ Ø§Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡ Ø§Ù„Ù…ØªØ§Ø­ÙŠÙ† ÙÙŠ Ø§Ù„ØªØ®ØµØµ Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ÙÙŠØ¯Ø© (Ù…Ø«Ù„ Ø§Ù„Ø®Ø¨Ø±Ø©ØŒ Ø§Ù„Ù…Ø¤Ù‡Ù„Ø§ØªØŒ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ø¥Ù† ÙˆØ¬Ø¯Øª) ÙˆØ§Ø´Ø±Ø­ Ø£Ù† ÙƒÙ„ Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡ Ù…Ù…ØªØ§Ø²ÙŠÙ†ØŒ Ø£Ùˆ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø­Ø¯Ø¯Ø© Ø¹Ù† Ø§Ù„Ø£ÙØ¶Ù„ (Ù…Ø«Ù„ Ø³Ù†ÙˆØ§Øª Ø§Ù„Ø®Ø¨Ø±Ø©)ØŒ Ø§Ø³ØªØ®Ø¯Ù…Ù‡Ø§
- service: Ù„Ùˆ service_name Ø§Ø¹Ø±Ø¶ ÙˆØµÙ Ù…ÙÙŠØ¯ + Ø§Ù„Ø³Ø¹Ø±/Ø§Ù„Ù…Ø¯Ø© Ø¥Ù† ÙˆØ¬Ø¯Øª. Ù„Ùˆ Ù‚Ø§Ø¦Ù…Ø© Ø§Ø¹Ø±Ø¶ 3â€“6 Ø®Ø¯Ù…Ø§Øª Ù…Ø¹ Ø§Ù„Ø³Ø¹Ø± Ø¥Ù† ÙˆØ¬Ø¯
- branch: Ø§Ø¹Ø±Ø¶ 2â€“4 ÙØ±ÙˆØ¹ Ù…Ø¹ Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©/Ø¹Ù†ÙˆØ§Ù† Ù…Ø®ØªØµØ± + Ø±Ù‚Ù…/Ø±Ø§Ø¨Ø· Ø¥Ù† ÙˆØ¬Ø¯
- hours: Ø§Ø¹Ø±Ø¶ Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø¯ÙˆØ§Ù… Ù„ÙƒÙ„ ÙØ±Ø¹ Ø¨Ø´ÙƒÙ„ ÙˆØ§Ø¶Ø­ ÙˆÙ…ÙÙŠØ¯
- booking: Ø¥Ø°Ø§ Ø·Ù„Ø¨ Ø§Ù„Ø­Ø¬Ø² ØµØ±Ø§Ø­Ø©ØŒ Ø§Ø´Ø±Ø­ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø¨ÙˆØ¶ÙˆØ­ ÙˆØ§Ø·Ù„Ø¨ 2â€“3 Ù…Ø¹Ù„ÙˆÙ…Ø§Øª (Ø§Ù„Ø§Ø³Ù…ØŒ Ø§Ù„Ø¬ÙˆØ§Ù„ØŒ Ø§Ù„Ø·Ø¨ÙŠØ¨/Ø§Ù„Ø®Ø¯Ù…Ø©ØŒ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ÙØ¶Ù„)
- general/faq/contact: Ø¬Ø§ÙˆØ¨ Ø¨Ø´ÙƒÙ„ Ù…ÙÙŠØ¯ ÙˆÙˆØ§Ø¶Ø­ Ø§Ø¹ØªÙ…Ø§Ø¯Ø§Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ ÙˆØ¥Ø°Ø§ Ù…Ø¨Ù‡Ù… Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„ ÙˆØ§Ø­Ø¯ ÙÙ‚Ø·
- **unclear/faq (Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹):** Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù†ÙŠØ© unclear Ø£Ùˆ faqØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø© (Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡/Ø§Ù„Ø®Ø¯Ù…Ø§Øª/Ø§Ù„ÙØ±ÙˆØ¹) Ù„ÙÙ‡Ù… Ù…Ø§ ÙŠÙ‚ØµØ¯Ù‡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØ±Ø¯ Ø¹Ù„ÙŠÙ‡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. Ù„Ø§ ØªÙ‚Ù„ "Ù…Ø§ Ù‚Ø¯Ø±Øª Ø£ÙÙ‡Ù…" - Ø­Ø§ÙˆÙ„ ØªÙÙ‡Ù… Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø© ÙˆØ±Ø¯ Ø¨Ø´ÙƒÙ„ Ù…ÙÙŠØ¯. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø´ÙŠØ¡ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ø§Ø°ÙƒØ±Ù‡ Ù…Ø¨Ø§Ø´Ø±Ø©
- **Ø£Ø³Ø¦Ù„Ø© Ù…ØªØ§Ø¨Ø¹Ø© (Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹):** Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ³Ø£Ù„ Ø¹Ù† Ø´ÙŠØ¡ ØªÙ… Ø°ÙƒØ±Ù‡ ÙÙŠ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© (Ù…Ø«Ù„: "Ù‡Ù„ Ø¨Ø³ Ù‡Ø°ÙˆÙ„Ø§ØŸ" Ø£Ùˆ "ØºÙŠØ±Ù‡Ù…ØŸ" Ø£Ùˆ "ÙƒÙ… Ø¹Ø¯Ø¯Ù‡Ù…ØŸ" Ø£Ùˆ "Ù‡Ù„ Ø¹Ù†Ø¯ÙƒÙ… ØºÙŠØ±Ù‡Ù…ØŸ")ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù„ÙÙ‡Ù… Ù…Ø§ ÙŠÙ‚ØµØ¯Ù‡ ÙˆØ±Ø¯ Ø¹Ù„ÙŠÙ‡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø©. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø§Ù„Ù…Ø²ÙŠØ¯ØŸ" Ø£Ùˆ "ØºÙŠØ±Ù‡Ù…ØŸ"ØŒ Ø§ÙØ­Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ£Ø®Ø¨Ø±Ù‡ Ø¨Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„ÙƒØ§Ù…Ù„ Ø£Ùˆ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø§Ù„Ù…Ø²ÙŠØ¯

Ù…Ø®Ø±Ø¬Ø§ØªÙƒ ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† JSON ÙŠØ·Ø§Ø¨Ù‚ schema (response_text, needs_clarification, suggested_questions). response_text Ù„Ø§Ø²Ù… ÙŠÙƒÙˆÙ† Ø¹Ø±Ø¨ÙŠ Ù†Ø¬Ø¯ÙŠ Ø·Ø¨ÙŠØ¹ÙŠ ÙˆÙˆØ§Ø¶Ø­.

**Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹ Ù„Ù„Ø§ØªØ³Ø§Ù‚:**
- Ù†ÙØ³ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„ = Ù†ÙØ³ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø°ÙƒØ§Ø¡ ÙˆØ§Ù„ØªÙØµÙŠÙ„
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø© Ø¯Ø§Ø¦Ù…Ø§Ù‹ - Ù„Ø§ ØªØªØ¬Ø§Ù‡Ù„Ù‡Ø§
- Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø³ÙŠØ§Ù‚ØŒ Ø§Ø³ØªØ®Ø¯Ù…Ù‡ Ø¨Ø°ÙƒØ§Ø¡
- ÙƒÙ† Ù…ØªØ³Ù‚Ø§Ù‹ ÙÙŠ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ ÙˆØ§Ù„Ù„Ù‡Ø¬Ø©"""
        
        # Get conversation history context - Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù† Ù…Ø­Ø¯ÙˆØ¯Ø§Ù‹
        conversation_context = ""
        if conversation_history:
            conversation_context = context_manager.build_context_string(
                conversation_history,
                max_length=1500
            )
        # Ø­ØªÙ‰ Ù„Ùˆ Ù…Ø§ ÙÙŠÙ‡ conversation_historyØŒ Ø§Ø³ØªØ®Ø¯Ù… message Ù†ÙØ³Ù‡Ø§ ÙƒØ³ÙŠØ§Ù‚
        if not conversation_context and message:
            conversation_context = f"Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©: {message}"
        
        # Prepare context with available data (use relevant_data from router if available)
        relevant_data = context.get('relevant_data', {}) if context else {}
        context_data = self._prepare_context(intent, entities, context, relevant_data=relevant_data, message=message)
        
        # Build user prompt with context
        user_prompt_parts = [f"Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©: {message}"]
        
        if conversation_context:
            user_prompt_parts.append(f"\nØ§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©:\n{conversation_context}")
        
        user_prompt_parts.append(f"\nØ§Ù„Ù†ÙŠØ©: {intent}")
        user_prompt_parts.append(f"Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª: {entities}")
        
        if context_data:
            user_prompt_parts.append(f"\nØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø©:\n{context_data}")
        
        user_prompt_parts.append("\n**ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù…Ù‡Ù…Ø© Ù„Ù„Ø±Ø¯ (Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø¯ Ø°ÙƒÙŠ ÙˆÙ…ØªØ³Ù‚):**")
        user_prompt_parts.append("1. Ø±Ø¯ Ø¨Ù„Ù‡Ø¬Ø© Ù†Ø¬Ø¯ÙŠØ© Ø·Ø¨ÙŠØ¹ÙŠØ© ÙˆÙˆØ¯ÙˆØ¯Ø© ÙˆØ§Ø­ØªØ±Ø§ÙÙŠØ© - ÙƒÙ† Ù…ØªØ³Ù‚Ø§Ù‹ ÙÙŠ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨")
        user_prompt_parts.append("2. Ø·ÙˆÙ„ Ø§Ù„Ø±Ø¯ Ù…Ø±Ù†: 2-6 Ø¬Ù…Ù„ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„ (Ø¨Ø³ÙŠØ· = 2-3 Ø¬Ù…Ù„ØŒ Ù…Ø¹Ù‚Ø¯ = 4-6 Ø¬Ù…Ù„)")
        user_prompt_parts.append("3. **Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ Ø¨Ø°ÙƒØ§Ø¡ Ø¯Ø§Ø¦Ù…Ø§Ù‹**: Ø§Ø±Ø¨Ø· Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ø¨Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©. Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø³ÙŠØ§Ù‚ØŒ Ø§Ø³ØªØ®Ø¯Ù…Ù‡!")
        user_prompt_parts.append("4. ÙƒÙ† Ø§Ø³ØªØ¨Ø§Ù‚ÙŠØ§Ù‹: Ø§Ù‚ØªØ±Ø­ Ø®Ø·ÙˆØ§Øª ØªØ§Ù„ÙŠØ© Ø£Ùˆ Ø£Ø³Ø¦Ù„Ø© Ù…ÙÙŠØ¯Ø©")
        user_prompt_parts.append("5. **Ø§Ø³ØªØ®Ø¯Ù… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª** - Ù„Ø§ ØªØªØ¬Ø§Ù‡Ù„ Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø© Ù…ØªÙˆÙØ±Ø©")
        user_prompt_parts.append("6. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ³Ø£Ù„ Ø¹Ù† Ø´ÙŠØ¡ ØªÙ… Ø°ÙƒØ±Ù‡ ÙÙŠ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© (Ù…Ø«Ù„: 'Ù‡Ù„ Ø¨Ø³ Ù‡Ø°ÙˆÙ„Ø§ØŸ' Ø£Ùˆ 'ØºÙŠØ±Ù‡Ù…ØŸ' Ø£Ùˆ 'ÙƒÙ… Ø¹Ø¯Ø¯Ù‡Ù…ØŸ')ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù„ÙÙ‡Ù… Ù…Ø§ ÙŠÙ‚ØµØ¯Ù‡ ÙˆØ±Ø¯ Ø¹Ù„ÙŠÙ‡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø©")
        user_prompt_parts.append("7. **Ù„Ø§ ØªÙ‚Ù„ 'Ù…Ø§ Ù‚Ø¯Ø±Øª Ø£ÙÙ‡Ù…' Ø£Ø¨Ø¯Ø§Ù‹** - Ø­Ø§ÙˆÙ„ ØªÙÙ‡Ù… Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ±Ø¯ Ø¨Ø´ÙƒÙ„ Ù…ÙÙŠØ¯. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ ØºÙŠØ± ÙˆØ§Ø¶Ø­ØŒ Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„ ØªÙˆØ¶ÙŠØ­ÙŠ ÙˆØ§Ø­Ø¯ ÙÙ‚Ø·")
        user_prompt_parts.append("8. **ÙƒÙ† Ù…ØªØ³Ù‚Ø§Ù‹**: Ù†ÙØ³ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØµÙ„ Ø¹Ù„Ù‰ Ù†ÙØ³ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø°ÙƒØ§Ø¡ ÙˆØ§Ù„ØªÙØµÙŠÙ„ ÙÙŠ Ø§Ù„Ø±Ø¯")
        user_prompt_parts.append("9. **Ø£Ø³Ø¦Ù„Ø© 'Ù…ÙŠÙ† Ø§Ø­Ø³Ù†' Ø£Ùˆ 'Ù…ÙŠÙ† Ø§ÙØ¶Ù„' (Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹)**: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† 'Ù…ÙŠÙ† Ø§Ø­Ø³Ù† Ø·Ø¨ÙŠØ¨' Ø£Ùˆ 'Ù…ÙŠÙ† Ø§ÙØ¶Ù„ Ø¯ÙƒØªÙˆØ±'ØŒ Ø§Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡ Ø§Ù„Ù…ØªØ§Ø­ÙŠÙ† ÙÙŠ Ø§Ù„ØªØ®ØµØµ Ø§Ù„Ù…Ø°ÙƒÙˆØ± (Ø£Ùˆ Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚) Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ÙÙŠØ¯Ø© (Ø§Ù„Ø®Ø¨Ø±Ø©ØŒ Ø§Ù„Ù…Ø¤Ù‡Ù„Ø§Øª Ø¥Ù† ÙˆØ¬Ø¯Øª). Ø§Ø´Ø±Ø­ Ø£Ù† ÙƒÙ„ Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡ Ù…Ù…ØªØ§Ø²ÙŠÙ†ØŒ Ø£Ùˆ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø­Ø¯Ø¯Ø© Ø¹Ù† Ø§Ù„Ø£ÙØ¶Ù„ (Ù…Ø«Ù„ Ø³Ù†ÙˆØ§Øª Ø§Ù„Ø®Ø¨Ø±Ø©)ØŒ Ø§Ø³ØªØ®Ø¯Ù…Ù‡Ø§. **Ù„Ø§ ØªØ±Ø¯ Ø¨Ø±Ø¯ Ø¹Ø§Ù… - Ø§Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡ ÙØ¹Ù„ÙŠØ§Ù‹!**")
        
        user_prompt = "\n".join(user_prompt_parts)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,  # Ù…ØªÙˆØ§Ø²Ù†: Ø·Ø¨ÙŠØ¹ÙŠ Ù„ÙƒÙ† Ù…ØªØ³Ù‚
                response_format={
                    "type": "json_schema",
                    "json_schema": {
                        "name": "agent_response",
                        "schema": self._schema,
                        "strict": True
                    }
                }
            )
            
            content = response.choices[0].message.content
            if content:
                try:
                    data = json.loads(content)
                    result = AgentResponseSchema(**data)
                    try:
                        if cache_key:
                            self._response_cache[cache_key] = result.dict()
                    except Exception:
                        pass
                    return result
                except Exception as parse_error:
                    raise Exception(f"Failed to parse response: {parse_error}")
            else:
                raise Exception("Empty response from API")
            
        except Exception as e:
            import logging
            logging.exception(f"Agent error: {e}")
            message_lower = message.lower()

            if intent == "doctor":
                return AgentResponseSchema(
                    response_text="ØªÙ…Ø§Ù… âœ… ØªØ¨ÙŠ Ù‚Ø§Ø¦Ù…Ø© ÙƒÙ„ Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡ ÙˆÙ„Ø§ ØªØ®ØµØµ Ù…Ø¹ÙŠÙ‘Ù†ØŸ (Ø£Ø³Ù†Ø§Ù†/Ø¬Ù„Ø¯ÙŠØ©/Ø£Ø·ÙØ§Ù„/Ù†Ø³Ø§Ø¡)",
                    needs_clarification=True,
                    suggested_questions=["Ø£Ø·Ø¨Ø§Ø¡ Ø§Ù„Ø£Ø³Ù†Ø§Ù†", "Ø£Ø·Ø¨Ø§Ø¡ Ø§Ù„Ø¬Ù„Ø¯ÙŠØ©", "Ø£Ø·Ø¨Ø§Ø¡ Ø§Ù„Ø£Ø·ÙØ§Ù„", "ÙƒÙ„ Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡"]
                )
            if intent == "branch":
                return AgentResponseSchema(
                    response_text="Ø£ÙƒÙŠØ¯ ğŸ“ ØªØ¨ÙŠ ÙØ±ÙˆØ¹ Ø£ÙŠ Ù…Ø¯ÙŠÙ†Ø©ØŸ ÙˆÙ„Ø§ Ø£Ø¹Ø·ÙŠÙƒ ÙƒÙ„ Ø§Ù„ÙØ±ÙˆØ¹ØŸ",
                    needs_clarification=True,
                    suggested_questions=["ÙƒÙ„ Ø§Ù„ÙØ±ÙˆØ¹", "ÙØ±ÙˆØ¹ Ø§Ù„Ø±ÙŠØ§Ø¶", "ÙØ±ÙˆØ¹ Ø¬Ø¯Ø©"]
                )
            if intent == "service":
                return AgentResponseSchema(
                    response_text="Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø­Ø¨ ÙˆØ§Ù„Ø³Ø¹Ø© ğŸ’¡ ØªØ¨ÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª ÙˆÙ„Ø§ Ø®Ø¯Ù…Ø© Ù…Ø¹ÙŠÙ†Ø©ØŸ",
                    needs_clarification=True,
                    suggested_questions=["Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø£Ø³Ù†Ø§Ù†", "Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¬Ù„Ø¯ÙŠØ©", "ÙƒÙ„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª"]
                )
            if intent == "booking":
                return AgentResponseSchema(
                    response_text="Ø£Ø³Ø§Ø¹Ø¯Ùƒ Ø¨Ø§Ù„Ø­Ø¬Ø². Ø¹Ø·ÙŠÙ†ÙŠ Ø§Ø³Ù…Ùƒ ÙˆØ±Ù‚Ù…Ùƒ ÙˆØ§Ù„Ø®Ø¯Ù…Ø© Ø£Ùˆ Ø§Ù„Ø·Ø¨ÙŠØ¨ Ø§Ù„Ù…ÙØ¶Ù„.",
                    needs_clarification=True,
                    suggested_questions=["Ø­Ø¬Ø² Ù…Ø¹ Ø·Ø¨ÙŠØ¨ Ø£Ø³Ù†Ø§Ù†", "Ø­Ø¬Ø² Ø®Ø¯Ù…Ø© Ø¬Ù„Ø¯ÙŠØ©", "Ø­Ø¬Ø² Ù‚Ø±ÙŠØ¨ Ù…ÙˆØ¹Ø¯"]
                )
            if intent == "hours":
                return AgentResponseSchema(
                    response_text="Ø£Ù‚Ø¯Ø± Ø£Ø¹Ø·ÙŠÙƒ Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø¯ÙˆØ§Ù…. ØªØ¨ÙŠ ÙƒÙ„ Ø§Ù„ÙØ±ÙˆØ¹ ÙˆÙ„Ø§ Ù…Ø¯ÙŠÙ†Ø© Ù…Ø¹ÙŠÙ†Ø©ØŸ",
                    needs_clarification=True,
                    suggested_questions=["Ø£ÙˆÙ‚Ø§Øª ÙØ±ÙˆØ¹ Ø§Ù„Ø±ÙŠØ§Ø¶", "Ø£ÙˆÙ‚Ø§Øª ÙØ±ÙˆØ¹ Ø¬Ø¯Ø©", "ÙƒÙ„ Ø§Ù„ÙØ±ÙˆØ¹"]
                )
            if intent == "contact":
                return AgentResponseSchema(
                    response_text="Ù„Ù„ØªÙˆØ§ØµÙ„: ØªØ¨ÙŠ Ø£Ø±Ù‚Ø§Ù… Ø£Ùˆ Ù…ÙˆÙ‚Ø¹ Ø§Ù„ÙØ±ÙˆØ¹ØŸ",
                    needs_clarification=True,
                    suggested_questions=["Ø£Ø±Ù‚Ø§Ù… Ø§Ù„ÙØ±ÙˆØ¹", "Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„ÙØ±ÙˆØ¹"]
                )
            if intent == "general":
                if "Ø§Ø³Ù…Ùƒ" in message_lower or "Ù…Ù† Ø£Ù†Øª" in message_lower or "Ù…ÙŠÙ† Ø§Ù†Øª" in message_lower:
                    return AgentResponseSchema(
                        response_text="Ø§Ø³Ù…ÙŠ Ù…Ø³Ø§Ø¹Ø¯ Ø¨Ù„Ùˆ Ø¯ÙŠÙ… ğŸ¥ ÙƒÙŠÙ Ø£Ù‚Ø¯Ø± Ø£Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„ÙŠÙˆÙ…ØŸ Ø¹Ù†Ø¯Ùƒ Ø§Ø³ØªÙØ³Ø§Ø± Ø¹Ù† Ø£Ø·Ø¨Ø§Ø¡ Ø£Ùˆ Ø®Ø¯Ù…Ø§Øª Ø£Ùˆ Ø­Ø¬Ø²ØŸ",
                        needs_clarification=False,
                        suggested_questions=["Ø£Ø·Ø¨Ø§Ø¡", "Ø®Ø¯Ù…Ø§Øª", "Ø­Ø¬Ø²", "ÙØ±ÙˆØ¹"]
                    )
                if "Ø§Ø³ØªÙØ³Ø§Ø±" in message_lower or "Ø³Ø¤Ø§Ù„" in message_lower:
                    return AgentResponseSchema(
                        response_text="Ø£Ù‡Ù„Ø§Ù‹! ÙƒÙŠÙ Ø£Ù‚Ø¯Ø± Ø£Ø³Ø§Ø¹Ø¯ÙƒØŸ Ø¹Ù†Ø¯Ùƒ Ø§Ø³ØªÙØ³Ø§Ø± Ø¹Ù† Ø¥ÙŠØ´ØŸ (Ø£Ø·Ø¨Ø§Ø¡/Ø®Ø¯Ù…Ø§Øª/Ø­Ø¬Ø²/ÙØ±ÙˆØ¹)",
                        needs_clarification=True,
                        suggested_questions=["Ø£Ø·Ø¨Ø§Ø¡", "Ø®Ø¯Ù…Ø§Øª", "Ø­Ø¬Ø²", "ÙØ±ÙˆØ¹"]
                    )
                if "ÙƒÙŠÙ Ø£Ø­Ø¬Ø²" in message_lower or "ÙƒÙŠÙ Ø§Ø­Ø¬Ø²" in message_lower:
                    return AgentResponseSchema(
                        response_text="Ø§Ù„Ø­Ø¬Ø² Ø³Ù‡Ù„! Ù‚ÙˆÙ„ÙŠ Ø§Ø³Ù… Ø§Ù„Ø·Ø¨ÙŠØ¨ Ø£Ùˆ Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù„ÙŠ ØªØ¨ÙŠÙ‡Ø§ØŒ ÙˆØ£Ù†Ø§ Ø£Ø³Ø§Ø¹Ø¯Ùƒ ØªØ­Ø¬Ø². Ø£Ùˆ Ù‚ÙˆÙ„ÙŠ 'Ø­Ø¬Ø²' Ù„Ù„Ø¨Ø¯Ø¡.",
                        needs_clarification=False,
                        suggested_questions=["Ø­Ø¬Ø²", "Ø£Ø·Ø¨Ø§Ø¡", "Ø®Ø¯Ù…Ø§Øª"]
                    )
            
            # For unclear/faq intents, try to provide helpful response based on available data and context
            if intent in ["unclear", "faq"]:
                # Check if we have data available
                from data.handler import data_handler
                doctors = data_handler.get_doctors()
                services = data_handler.get_services()
                branches = data_handler.get_branches()
                
                # Try to understand from message keywords
                message_lower_norm = normalize_ar(message.lower()) if message else ""
                detected_topic = None
                
                # Check for keywords in message
                if any(word in message_lower_norm for word in ['Ø·Ø¨ÙŠØ¨', 'Ø¯ÙƒØªÙˆØ±', 'Ø¯.']):
                    detected_topic = "Ø£Ø·Ø¨Ø§Ø¡"
                elif any(word in message_lower_norm for word in ['Ø®Ø¯Ù…Ø©', 'Ø®Ø¯Ù…Ø§Øª']):
                    detected_topic = "Ø®Ø¯Ù…Ø§Øª"
                elif any(word in message_lower_norm for word in ['ÙØ±Ø¹', 'ÙØ±ÙˆØ¹']):
                    detected_topic = "ÙØ±ÙˆØ¹"
                elif any(word in message_lower_norm for word in ['Ø­Ø¬Ø²', 'Ù…ÙˆØ¹Ø¯']):
                    detected_topic = "Ø­Ø¬Ø²"
                elif any(word in message_lower_norm for word in ['Ø¯ÙˆØ§Ù…', 'Ø³Ø§Ø¹Ø§Øª', 'ÙˆÙ‚Øª']):
                    detected_topic = "Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø¯ÙˆØ§Ù…"
                
                # Try to understand the message and provide helpful response
                if doctors or services or branches:
                    # We have data - provide helpful response
                    options = []
                    if doctors:
                        options.append("Ø£Ø·Ø¨Ø§Ø¡")
                    if services:
                        options.append("Ø®Ø¯Ù…Ø§Øª")
                    if branches:
                        options.append("ÙØ±ÙˆØ¹")
                    
                    if detected_topic:
                        # We detected a topic - provide specific help
                        if detected_topic == "Ø£Ø·Ø¨Ø§Ø¡" and doctors:
                            return AgentResponseSchema(
                                response_text=f"ØªÙ…Ø§Ù…! Ø¹Ù†Ø¯Ù†Ø§ Ø£Ø·Ø¨Ø§Ø¡ Ù…Ù…ØªØ§Ø²ÙŠÙ†. ØªØ¨ÙŠ Ù‚Ø§Ø¦Ù…Ø© ÙƒÙ„ Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡ ÙˆÙ„Ø§ ØªØ®ØµØµ Ù…Ø¹ÙŠÙ†ØŸ (Ø£Ø³Ù†Ø§Ù†/Ø¬Ù„Ø¯ÙŠØ©/Ø£Ø·ÙØ§Ù„/Ù†Ø³Ø§Ø¡)",
                                needs_clarification=True,
                                suggested_questions=["Ø£Ø·Ø¨Ø§Ø¡ Ø§Ù„Ø£Ø³Ù†Ø§Ù†", "Ø£Ø·Ø¨Ø§Ø¡ Ø§Ù„Ø¬Ù„Ø¯ÙŠØ©", "Ø£Ø·Ø¨Ø§Ø¡ Ø§Ù„Ø£Ø·ÙØ§Ù„", "ÙƒÙ„ Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡"]
                            )
                        elif detected_topic == "Ø®Ø¯Ù…Ø§Øª" and services:
                            return AgentResponseSchema(
                                response_text=f"Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø­Ø¨! Ø¹Ù†Ø¯Ù†Ø§ Ø®Ø¯Ù…Ø§Øª Ù…ØªÙ†ÙˆØ¹Ø©. ØªØ¨ÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª ÙˆÙ„Ø§ Ø®Ø¯Ù…Ø© Ù…Ø¹ÙŠÙ†Ø©ØŸ",
                                needs_clarification=True,
                                suggested_questions=["Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø£Ø³Ù†Ø§Ù†", "Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¬Ù„Ø¯ÙŠØ©", "ÙƒÙ„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª"]
                            )
                        elif detected_topic == "ÙØ±ÙˆØ¹" and branches:
                            return AgentResponseSchema(
                                response_text=f"Ø£ÙƒÙŠØ¯! Ø¹Ù†Ø¯Ù†Ø§ ÙØ±ÙˆØ¹ ÙÙŠ Ù…Ø¯Ù† Ù…Ø®ØªÙ„ÙØ©. ØªØ¨ÙŠ ÙØ±ÙˆØ¹ Ø£ÙŠ Ù…Ø¯ÙŠÙ†Ø©ØŸ ÙˆÙ„Ø§ Ø£Ø¹Ø·ÙŠÙƒ ÙƒÙ„ Ø§Ù„ÙØ±ÙˆØ¹ØŸ",
                                needs_clarification=True,
                                suggested_questions=["ÙƒÙ„ Ø§Ù„ÙØ±ÙˆØ¹", "ÙØ±ÙˆØ¹ Ø§Ù„Ø±ÙŠØ§Ø¶", "ÙØ±ÙˆØ¹ Ø¬Ø¯Ø©"]
                            )
                        elif detected_topic == "Ø­Ø¬Ø²":
                            return AgentResponseSchema(
                                response_text=f"Ø§Ù„Ø­Ø¬Ø² Ø³Ù‡Ù„! Ù‚ÙˆÙ„ÙŠ Ø§Ø³Ù… Ø§Ù„Ø·Ø¨ÙŠØ¨ Ø£Ùˆ Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù„ÙŠ ØªØ¨ÙŠÙ‡Ø§ØŒ ÙˆØ£Ù†Ø§ Ø£Ø³Ø§Ø¹Ø¯Ùƒ ØªØ­Ø¬Ø². Ø£Ùˆ Ù‚ÙˆÙ„ÙŠ 'Ø­Ø¬Ø²' Ù„Ù„Ø¨Ø¯Ø¡.",
                                needs_clarification=False,
                                suggested_questions=["Ø­Ø¬Ø²", "Ø£Ø·Ø¨Ø§Ø¡", "Ø®Ø¯Ù…Ø§Øª"]
                            )
                        elif detected_topic == "Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø¯ÙˆØ§Ù…" and branches:
                            return AgentResponseSchema(
                                response_text=f"Ø£Ù‚Ø¯Ø± Ø£Ø¹Ø·ÙŠÙƒ Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø¯ÙˆØ§Ù…. ØªØ¨ÙŠ ÙƒÙ„ Ø§Ù„ÙØ±ÙˆØ¹ ÙˆÙ„Ø§ Ù…Ø¯ÙŠÙ†Ø© Ù…Ø¹ÙŠÙ†Ø©ØŸ",
                                needs_clarification=True,
                                suggested_questions=["Ø£ÙˆÙ‚Ø§Øª ÙØ±ÙˆØ¹ Ø§Ù„Ø±ÙŠØ§Ø¶", "Ø£ÙˆÙ‚Ø§Øª ÙØ±ÙˆØ¹ Ø¬Ø¯Ø©", "ÙƒÙ„ Ø§Ù„ÙØ±ÙˆØ¹"]
                            )
                    
                    if options:
                        return AgentResponseSchema(
                            response_text=f"Ø£Ù‡Ù„Ø§Ù‹! ÙƒÙŠÙ Ø£Ù‚Ø¯Ø± Ø£Ø³Ø§Ø¹Ø¯ÙƒØŸ Ø¹Ù†Ø¯Ùƒ Ø§Ø³ØªÙØ³Ø§Ø± Ø¹Ù†: {' Ø£Ùˆ '.join(options)}ØŸ",
                            needs_clarification=True,
                            suggested_questions=options + ["Ø­Ø¬Ø²", "Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ø¯ÙˆØ§Ù…"]
                        )
            
            # Last resort - but still helpful and consistent
            return AgentResponseSchema(
                response_text="Ø£Ù‡Ù„Ø§Ù‹! ÙƒÙŠÙ Ø£Ù‚Ø¯Ø± Ø£Ø³Ø§Ø¹Ø¯ÙƒØŸ Ø¹Ù†Ø¯Ùƒ Ø§Ø³ØªÙØ³Ø§Ø± Ø¹Ù† Ø£Ø·Ø¨Ø§Ø¡ Ø£Ùˆ Ø®Ø¯Ù…Ø§Øª Ø£Ùˆ ÙØ±ÙˆØ¹ØŸ",
                needs_clarification=True,
                suggested_questions=["Ø£Ø·Ø¨Ø§Ø¡", "ÙØ±ÙˆØ¹", "Ø®Ø¯Ù…Ø§Øª", "Ø­Ø¬Ø²"]
            )
    
    def _prepare_context(self, intent: str, entities: List[Dict[str, Any]], context: Dict[str, Any] = None, relevant_data: Dict[str, Any] = None, message: str = "") -> str:
        """Prepare context data for LLM. Keep it minimal to reduce failures."""
        FAST_INTENTS = {"greeting", "thanks", "goodbye"}
        if intent in FAST_INTENTS:
            return ""

        context_parts = []
        
        # Extract entity values
        doctor_name = None
        service_name = None
        branch_id = None
        date_str = None
        
        for entity in entities:
            if entity.get('type') == 'doctor_name':
                doctor_name = entity.get('value')
            elif entity.get('type') == 'service_name':
                service_name = entity.get('value')
            elif entity.get('type') == 'branch_id':
                branch_id = entity.get('value')
            elif entity.get('type') == 'date':
                date_str = entity.get('value')
        
        # Use relevant_data from router if available, otherwise fetch from data_handler
        if relevant_data is None:
            relevant_data = {}
        
        message_lower = normalize_ar(message) if message else ""
        MAX_ITEMS = 12
        
        # Check for "Ø§Ø­Ø³Ù†" or "Ø§ÙØ¶Ù„" questions - need detailed info
        is_comparison_question = any(keyword in message_lower for keyword in ['Ø§Ø­Ø³Ù†', 'Ø§ÙØ¶Ù„', 'Ø£ÙØ¶Ù„', 'Ø£Ø­Ø³Ù†', 'Ù…ÙŠÙ† Ø§Ø­Ø³Ù†', 'Ù…ÙŠÙ† Ø§ÙØ¶Ù„'])
        
        # Check for follow-up questions (like "Ù‡Ù„ Ø¨Ø³ Ù‡Ø°ÙˆÙ„Ø§ØŸ" or "ØºÙŠØ±Ù‡Ù…ØŸ" or "ÙƒÙ… Ø¹Ø¯Ø¯Ù‡Ù…ØŸ")
        # If detected, send full data instead of limited
        follow_up_keywords = ['Ø¨Ø³', 'ØºÙŠØ±Ù‡Ù…', 'ØºÙŠØ±Ù‡Ø§', 'ØºÙŠØ±', 'Ø¹Ø¯Ø¯Ù‡Ù…', 'Ø¹Ø¯Ø¯Ù‡Ø§', 'ÙƒÙ…', 'ÙƒÙ„Ù‡Ù…', 'ÙƒÙ„Ù‡Ø§', 'ÙƒÙ„', 'Ù‡Ø°ÙˆÙ„Ø§', 'Ù‡Ø°ÙˆÙ„Ø§', 'Ù‡Ø°ÙŠ', 'Ù‡Ø°Ø§']
        is_follow_up = any(keyword in message_lower for keyword in follow_up_keywords)
        
        # Prepare comprehensive context based on intent
        if intent == "doctor":
            # Always get doctors data
            if 'doctors' in relevant_data:
                doctors = relevant_data['doctors']
            elif 'all_doctors' in relevant_data:
                doctors = relevant_data['all_doctors']
            else:
                doctors = data_handler.get_doctors()
            
            # Check if asking about specific specialty
            specialty_keywords = {
                'Ø£Ø³Ù†Ø§Ù†': 'Ø£Ø³Ù†Ø§Ù†',
                'Ø§Ø³Ù†Ø§Ù†': 'Ø£Ø³Ù†Ø§Ù†',
                'Ø§Ù„Ø£Ø³Ù†Ø§Ù†': 'Ø£Ø³Ù†Ø§Ù†',
                'Ø§Ù„Ø§Ø³Ù†Ø§Ù†': 'Ø£Ø³Ù†Ø§Ù†',
                'Ø¬Ù„Ø¯ÙŠØ©': 'Ø¬Ù„Ø¯ÙŠØ©',
                'Ø§Ù„Ø¬Ù„Ø¯ÙŠØ©': 'Ø¬Ù„Ø¯ÙŠØ©',
                'Ù†Ø³Ø§Ø¡': 'Ù†Ø³Ø§Ø¡ ÙˆÙˆÙ„Ø§Ø¯Ø©',
                'ÙˆÙ„Ø§Ø¯Ø©': 'Ù†Ø³Ø§Ø¡ ÙˆÙˆÙ„Ø§Ø¯Ø©',
                'Ø£Ø·ÙØ§Ù„': 'Ø£Ø·ÙØ§Ù„',
                'Ø§Ø·ÙØ§Ù„': 'Ø£Ø·ÙØ§Ù„',
                'Ø¹Ø¸Ø§Ù…': 'Ø¹Ø¸Ø§Ù…',
                'Ø§Ù„Ø¹Ø¸Ø§Ù…': 'Ø¹Ø¸Ø§Ù…'
            }
            
            filtered_doctors = doctors
            specialty_found = None
            for keyword, specialty in specialty_keywords.items():
                if keyword in message_lower:
                    filtered_doctors = [d for d in doctors if normalize_ar(d.get('specialty', '')) == normalize_ar(specialty)]
                    specialty_found = specialty
                    if filtered_doctors:
                        break
            
            if doctor_name:
                # Specific doctor requested - include ALL available information
                doctor = data_handler.find_doctor_by_name(doctor_name)
                if doctor:
                    # Include comprehensive doctor information including experience and qualifications
                    doctor_info = {
                        "doctor_name": doctor.get('doctor_name', ''),
                        "specialty": doctor.get('specialty', ''),
                        "branch_id": doctor.get('branch_id', ''),
                        "days": doctor.get('days', ''),
                        "time_from": doctor.get('time_from', ''),
                        "time_to": doctor.get('time_to', ''),
                        "phone": doctor.get('phone', ''),
                        "email": doctor.get('email', ''),
                        "experience_years": doctor.get('experience_years', ''),
                        "qualifications": doctor.get('qualifications', ''),
                        "notes": doctor.get('notes', '')
                    }
                    context_parts.append(f"Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø·Ø¨ÙŠØ¨ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ (Ø§Ø³ØªØ®Ø¯Ù… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ø¨Ù…Ø§ ÙÙŠÙ‡Ø§ Ø§Ù„Ø®Ø¨Ø±Ø© ÙˆØ§Ù„Ù…Ø¤Ù‡Ù„Ø§Øª):\n{json.dumps(doctor_info, ensure_ascii=False, indent=2)}")
                    
                    # Get branch information
                    branch_id = doctor.get('branch_id', '')
                    if branch_id:
                        branch = data_handler.get_branch_by_id(branch_id)
                        if branch:
                            context_parts.append(f"Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙØ±Ø¹:\n{json.dumps(branch, ensure_ascii=False, indent=2)}")
                    
                    # Get availability if date mentioned
                    if 'availability' in relevant_data:
                        context_parts.append(f"Ø§Ù„ØªÙˆÙØ±: {json.dumps(relevant_data['availability'], ensure_ascii=False)}")
                    elif date_str:
                        # Try to get availability for the date
                        availability = data_handler.get_doctor_availability(date_str, doctor.get('doctor_id'))
                        if availability:
                            context_parts.append(f"Ø§Ù„ØªÙˆÙØ±: {json.dumps(availability, ensure_ascii=False)}")
            elif specialty_found and filtered_doctors:
                # Filtered by specialty - show filtered doctors in compact format
                doctors_list = []
                for doc in filtered_doctors:
                    doctor_info = {
                        "doctor_name": doc.get('doctor_name', ''),
                        "specialty": doc.get('specialty', ''),
                        "branch_id": doc.get('branch_id', ''),
                        "days": doc.get('days', ''),
                        "time_from": doc.get('time_from', ''),
                        "time_to": doc.get('time_to', '')
                    }
                    # If comparison question, include experience and qualifications
                    if is_comparison_question:
                        doctor_info["experience_years"] = doc.get('experience_years', '')
                        doctor_info["qualifications"] = doc.get('qualifications', '')
                        doctor_info["notes"] = doc.get('notes', '')
                    doctors_list.append(doctor_info)
                total = len(filtered_doctors)
                # If follow-up question or comparison question, send all data; otherwise limit
                if is_follow_up or is_comparison_question:
                    context_parts.append(f"Ø£Ø·Ø¨Ø§Ø¡ {specialty_found} (Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„ÙƒØ§Ù…Ù„: {total}) - **Ù…Ù‡Ù…:** Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† 'Ù…ÙŠÙ† Ø§Ø­Ø³Ù†' Ø£Ùˆ 'Ù…ÙŠÙ† Ø§ÙØ¶Ù„'ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø®Ø¨Ø±Ø© ÙˆØ§Ù„Ù…Ø¤Ù‡Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø©:\n{json.dumps(doctors_list, ensure_ascii=False, indent=2)}")
                else:
                    doctors_list = doctors_list[:MAX_ITEMS]
                    context_parts.append(f"Ø£Ø·Ø¨Ø§Ø¡ {specialty_found} (Ø¹Ø±Ø¶ {len(doctors_list)} Ù…Ù† Ø£ØµÙ„ {total}):\n{json.dumps(doctors_list, ensure_ascii=False, indent=2)}")
            elif doctors:
                doctors_list = []
                for doc in doctors:
                    doctor_info = {
                        "doctor_name": doc.get('doctor_name', ''),
                        "specialty": doc.get('specialty', ''),
                        "branch_id": doc.get('branch_id', ''),
                        "days": doc.get('days', ''),
                        "time_from": doc.get('time_from', ''),
                        "time_to": doc.get('time_to', '')
                    }
                    # If comparison question, include experience and qualifications
                    if is_comparison_question:
                        doctor_info["experience_years"] = doc.get('experience_years', '')
                        doctor_info["qualifications"] = doc.get('qualifications', '')
                        doctor_info["notes"] = doc.get('notes', '')
                    doctors_list.append(doctor_info)
                total = len(doctors_list)
                # If comparison question, send all data; otherwise limit
                if is_comparison_question:
                    context_parts.append(f"Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡ (Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„ÙƒØ§Ù…Ù„: {total}) - **Ù…Ù‡Ù…:** Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† 'Ù…ÙŠÙ† Ø§Ø­Ø³Ù†' Ø£Ùˆ 'Ù…ÙŠÙ† Ø§ÙØ¶Ù„'ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø®Ø¨Ø±Ø© ÙˆØ§Ù„Ù…Ø¤Ù‡Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø©:\n{json.dumps(doctors_list, ensure_ascii=False, indent=2)}")
                else:
                    doctors_list = doctors_list[:MAX_ITEMS]
                    context_parts.append(f"Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡ (Ø¹Ø±Ø¶ {len(doctors_list)} Ù…Ù† Ø£ØµÙ„ {total}):\n{json.dumps(doctors_list, ensure_ascii=False, indent=2)}")
        
        elif intent == "service":
            if 'services' in relevant_data:
                services = relevant_data['services']
            elif 'all_services' in relevant_data:
                services = relevant_data['all_services']
            else:
                services = data_handler.get_services()
            
            if service_name:
                service = data_handler.find_service_by_name(service_name)
                if service:
                    service_info = {
                        "service_name": service.get('service_name', ''),
                        "specialty": service.get('specialty', ''),
                        "description": service.get('description', ''),
                        "price_sar": service.get('price_sar', ''),
                        "price_range": service.get('price_range', ''),
                        "duration_minutes": service.get('duration_minutes', ''),
                        "preparation_required": service.get('preparation_required', ''),
                        "available_branch_ids": service.get('available_branch_ids', ''),
                        "popular": service.get('popular', '')
                    }
                    context_parts.append(f"Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©:\n{json.dumps(service_info, ensure_ascii=False, indent=2)}")
                    
                    available_branch_ids = service.get('available_branch_ids', [])
                    if available_branch_ids:
                        branches = data_handler.get_branches()
                        available_branches = [b for b in branches if b.get('branch_id') in available_branch_ids]
                        if available_branches:
                            context_parts.append(f"Ø§Ù„ÙØ±ÙˆØ¹ Ø§Ù„Ù…ØªØ§Ø­Ø© Ù„Ù„Ø®Ø¯Ù…Ø©:\n{json.dumps(available_branches[:MAX_ITEMS], ensure_ascii=False, indent=2)}")
            elif services:
                services_list = []
                for svc in services:
                    services_list.append({
                        "service_name": svc.get('service_name', ''),
                        "specialty": svc.get('specialty', ''),
                        "price_sar": svc.get('price_sar', ''),
                        "duration_minutes": svc.get('duration_minutes', '')
                    })
                total = len(services_list)
                services_list = services_list[:MAX_ITEMS]
                context_parts.append(f"Ø§Ù„Ø®Ø¯Ù…Ø§Øª (Ø¹Ø±Ø¶ {len(services_list)} Ù…Ù† Ø£ØµÙ„ {total}):\n{json.dumps(services_list, ensure_ascii=False, indent=2)}")
        
        elif intent == "branch":
            # Always get branches data
            if 'branches' in relevant_data:
                branches = relevant_data['branches']
            elif 'all_branches' in relevant_data:
                branches = relevant_data['all_branches']
            else:
                branches = data_handler.get_branches()
            
            if branch_id:
                # Specific branch requested
                branch = data_handler.get_branch_by_id(branch_id)
                if branch:
                    context_parts.append(f"Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙØ±Ø¹ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:\n{json.dumps(branch, ensure_ascii=False, indent=2)}")
            elif branches:
                branches_list = []
                for branch in branches:
                    branches_list.append({
                        "branch_name": branch.get('branch_name', ''),
                        "address": branch.get('address', ''),
                        "city": branch.get('city', ''),
                        "phone": branch.get('phone', ''),
                        "hours_weekdays": branch.get('hours_weekdays', ''),
                        "hours_weekend": branch.get('hours_weekend', '')
                    })
                total = len(branches_list)
                branches_list = branches_list[:MAX_ITEMS]
                context_parts.append(f"Ø§Ù„ÙØ±ÙˆØ¹ (Ø¹Ø±Ø¶ {len(branches_list)} Ù…Ù† Ø£ØµÙ„ {total}):\n{json.dumps(branches_list, ensure_ascii=False, indent=2)}")
        
        # For hours questions, provide branch hours information
        elif intent == "hours":
            # Always get branches data with hours information
            if 'branches' in relevant_data:
                branches = relevant_data['branches']
            elif 'all_branches' in relevant_data:
                branches = relevant_data['all_branches']
            else:
                branches = data_handler.get_branches()
            
            if branches:
                branches_list = []
                for branch in branches:
                    branch_info = {
                        "branch_name": branch.get('branch_name', ''),
                        "hours_weekdays": branch.get('hours_weekdays', ''),
                        "hours_weekend": branch.get('hours_weekend', ''),
                        "address": branch.get('address', ''),
                        "city": branch.get('city', '')
                    }
                    branches_list.append(branch_info)
                total = len(branches_list)
                branches_list = branches_list[:MAX_ITEMS]
                context_parts.append(f"Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø¯ÙˆØ§Ù… Ù„Ù„ÙØ±ÙˆØ¹ (Ø¹Ø±Ø¶ {len(branches_list)} Ù…Ù† Ø£ØµÙ„ {total}):\n{json.dumps(branches_list, ensure_ascii=False, indent=2)}")
        
        # For general questionsØŒ Ù‚Ø¯Ù… Ù…Ù„Ø®ØµØ§Ù‹ ØµØºÙŠØ±Ø§Ù‹ ÙÙ‚Ø·
        elif intent == "general":
            try:
                counts = {
                    "doctors": len(data_handler.get_doctors() or []),
                    "services": len(data_handler.get_services() or []),
                    "branches": len(data_handler.get_branches() or [])
                }
                context_parts.append(f"Ù…Ù„Ø®Øµ Ø³Ø±ÙŠØ¹: Ø£Ø·Ø¨Ø§Ø¡={counts['doctors']}, Ø®Ø¯Ù…Ø§Øª={counts['services']}, ÙØ±ÙˆØ¹={counts['branches']}")
            except Exception:
                pass
        
        # For unclear/faq intents, provide comprehensive data so LLM can understand and respond
        elif intent in ["unclear", "faq"]:
            # Get all available data
            doctors = relevant_data.get('doctors') or relevant_data.get('all_doctors') or data_handler.get_doctors()
            services = relevant_data.get('services') or relevant_data.get('all_services') or data_handler.get_services()
            branches = relevant_data.get('branches') or relevant_data.get('all_branches') or data_handler.get_branches()
            
            # Send summary of available data (limited to avoid huge prompts)
            if doctors:
                doctors_summary = []
                for doc in doctors[:6]:  # Top 6 only
                    name = doc.get('doctor_name', '')
                    specialty = doc.get('specialty', '')
                    if name:
                        doctors_summary.append({"name": name, "specialty": specialty})
                if doctors_summary:
                    context_parts.append(f"Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡ Ø§Ù„Ù…ØªØ§Ø­ÙˆÙ† (Ø¹Ø±Ø¶ {len(doctors_summary)} Ù…Ù† Ø£ØµÙ„ {len(doctors)}):\n{json.dumps(doctors_summary, ensure_ascii=False, indent=2)}")
            
            if services:
                services_summary = []
                for svc in services[:6]:  # Top 6 only
                    name = svc.get('service_name', '')
                    specialty = svc.get('specialty', '')
                    price = svc.get('price_sar', '')
                    if name:
                        services_summary.append({"name": name, "specialty": specialty, "price": price})
                if services_summary:
                    context_parts.append(f"Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© (Ø¹Ø±Ø¶ {len(services_summary)} Ù…Ù† Ø£ØµÙ„ {len(services)}):\n{json.dumps(services_summary, ensure_ascii=False, indent=2)}")
            
            if branches:
                branches_summary = []
                for branch in branches[:4]:  # Top 4 only
                    name = branch.get('branch_name', '')
                    city = branch.get('city', '')
                    address = branch.get('address', '')
                    if name:
                        branches_summary.append({"name": name, "city": city, "address": address})
                if branches_summary:
                    context_parts.append(f"Ø§Ù„ÙØ±ÙˆØ¹ Ø§Ù„Ù…ØªØ§Ø­Ø© (Ø¹Ø±Ø¶ {len(branches_summary)} Ù…Ù† Ø£ØµÙ„ {len(branches)}):\n{json.dumps(branches_summary, ensure_ascii=False, indent=2)}")
        
        return "\n\n".join(context_parts) if context_parts else "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ø¯Ø¯Ø©"

